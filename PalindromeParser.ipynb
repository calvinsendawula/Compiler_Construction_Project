{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU6OHyK8XRmS"
      },
      "source": [
        "Part 1: Lexical Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1EzLV7tlRoLu"
      },
      "outputs": [],
      "source": [
        "#importing Python's RegEx library\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "96HDe6oHDeYC"
      },
      "outputs": [],
      "source": [
        "# Function to split input sentence into tokens (words)\n",
        "def lexer(sentence):\n",
        "    # Using regular expression to split the sentence into tokens\n",
        "    # The regular expression pattern includes common punctuation and space as delimiters\n",
        "    return re.split(r\"[,|.|\\?|(|)| ]\", sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RAYQEUY1WFgx"
      },
      "outputs": [],
      "source": [
        "# Function to split input into tokens (characters)\n",
        "def enhanced_lexer(input_str):\n",
        "    # Define regular expressions for relevant tokens\n",
        "    letter_pattern = re.compile(r'[a-zA-Z]')           # Letters\n",
        "    digit_pattern = re.compile(r'\\d')                   # Digits\n",
        "    space_pattern = re.compile(r'\\s')                   # Space\n",
        "    punctuation_pattern = re.compile(r'[.,;:!?()-]')    # Common punctuation\n",
        "\n",
        "    # Tokenize the input string\n",
        "    tokens = []\n",
        "    for char in input_str:\n",
        "        if letter_pattern.match(char):\n",
        "            tokens.append(('LETTER', char.lower()))     # If the character is a letter, append ('LETTER', lowercase_char)\n",
        "        elif digit_pattern.match(char):\n",
        "            tokens.append(('DIGIT', char))              # If the character is a digit, append ('DIGIT', char)\n",
        "        elif space_pattern.match(char):\n",
        "            tokens.append(('SPACE', char))              # If the character is a space, append ('SPACE', char)\n",
        "        elif punctuation_pattern.match(char):\n",
        "            tokens.append(('PUNCTUATION', char))        # If the character is punctuation, append ('PUNCTUATION', char)\n",
        "        else:\n",
        "            tokens.append(('SPECIAL_CHARACTERS', char))  # If the character is none of the above, append ('SPECIAL_CHARACTERS', char)\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Tg0qT1Hthc7m"
      },
      "outputs": [],
      "source": [
        "#function to render tokens\n",
        "def renderTokens(tokens):\n",
        "  global token_counter\n",
        "  token_counter = 0\n",
        "  token_list = []\n",
        "\n",
        "  #formatting row + column heading\n",
        "  print(\"=\" * 50)\n",
        "  print(\"|\" \"\\t\", \"TOKEN NO\", \"\\t\", \"|\", \"\\t\", \" TOKEN\", \"\\t\" , \"|\")\n",
        "  print(\"=\" * 50)\n",
        "\n",
        "\n",
        "  for token in tokens:\n",
        "    if token != \"\":\n",
        "      token_counter += 1\n",
        "      token_list.append(token)\n",
        "\n",
        "      #formatting token rows + columns\n",
        "      print(\"|\", \"\\t\", token_counter, \"\\t\\t\", \"|\", \"\\t\", token)\n",
        "      print(\"-\"*50)\n",
        "  token_counter = 0\n",
        "  return token_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87_vGfh6XbIH"
      },
      "source": [
        "Part 2: Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-U2n-H_WP9Lf"
      },
      "outputs": [],
      "source": [
        "# Parser function: Generates an Abstract Syntax Tree (AST) from tokens\n",
        "def parse(tokens):\n",
        "    current_token = None  # Initialize the current token\n",
        "    index = -1  # Initialize the index for tokens\n",
        "\n",
        "    def next_token():  # Define a function to get the next token\n",
        "        nonlocal current_token, index  # Access variables from the outer scope\n",
        "        index += 1  # Move to the next token index\n",
        "        if index < len(tokens):  # Check if the index is within the token list\n",
        "            current_token = tokens[index]  # Set the current token\n",
        "        else:\n",
        "            current_token = None  # Set current token to None if no more tokens exist\n",
        "\n",
        "    # Parses an expression\n",
        "    def expression():  # Define function to parse an expression\n",
        "        nonlocal current_token  # Access the current token from the outer scope\n",
        "        if current_token != \"\":  # Check if the token is a valid expression type\n",
        "            node = current_token  # Store the current token\n",
        "            next_token()  # Move to the next token\n",
        "            return node  # Return the node\n",
        "        else:\n",
        "            raise SyntaxError(\"Invalid expression\")  # Raise an error for an invalid expression\n",
        "\n",
        "    # Parses a palindrome (for this example, it's the same as an expression)\n",
        "    def palindrome():  # Define function to parse a palindrome\n",
        "        return expression()  # Return the result of parsing an expression\n",
        "\n",
        "    next_token()  # Start by getting the next token\n",
        "\n",
        "    ast = palindrome()  # Generate an AST by treating the input as a palindrome\n",
        "    if current_token is not None:  # Check for invalid syntax\n",
        "        raise SyntaxError(\"Invalid syntax\")  # Raise an error for invalid syntax\n",
        "\n",
        "    return ast  # Return the Abstract Syntax Tree\n",
        "\n",
        "# Function to check if the input is a palindrome using Recursive Descent Parser\n",
        "def is_palindrome(input_string):\n",
        "    global i\n",
        "    i=0\n",
        "\n",
        "    #function for starting symbol that recursively calls itslef when S is encountered\n",
        "    def S(s):\n",
        "        if len(s) == 0:\n",
        "            return True\n",
        "        if len(s) == 1:\n",
        "            return match(s)\n",
        "        elif (s[0] == s[-1]):\n",
        "            if(match(s[0])):\n",
        "              return S(s[1:-1])\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    #used to match input\n",
        "    def match(a):\n",
        "      global i\n",
        "      if(i >= len(input_string)):\n",
        "        return False\n",
        "      elif(input_string[i] == a):\n",
        "        i+=1\n",
        "        return True\n",
        "      else:\n",
        "        return False\n",
        "\n",
        "    return S(input_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsAaOB-nXe29"
      },
      "source": [
        "An example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y8zTmxlQJou",
        "outputId": "8ed9bc39-0fee-4d16-9015-975f9181d191"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a string or number: mama\n",
            "==================================================\n",
            "|\t TOKEN NO \t | \t  TOKEN \t |\n",
            "==================================================\n",
            "| \t 1 \t\t | \t mama\n",
            "--------------------------------------------------\n",
            "\n",
            "Token List:['mama']\n",
            "Tokens: ['mama']\n",
            "==================================================\n",
            "|\t TOKEN NO \t | \t  TOKEN \t |\n",
            "==================================================\n",
            "| \t 1 \t\t | \t ('LETTER', 'm')\n",
            "--------------------------------------------------\n",
            "| \t 2 \t\t | \t ('LETTER', 'a')\n",
            "--------------------------------------------------\n",
            "| \t 3 \t\t | \t ('LETTER', 'm')\n",
            "--------------------------------------------------\n",
            "| \t 4 \t\t | \t ('LETTER', 'a')\n",
            "--------------------------------------------------\n",
            "\n",
            "Token List:[('LETTER', 'm'), ('LETTER', 'a'), ('LETTER', 'm'), ('LETTER', 'a')]\n",
            "The input 'mama' is not a palindrome.\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "input_text = input(\"Enter a string or number: \")  # Prompt the user to enter a string or number\n",
        "\n",
        "# Tokenize the user input using the normal lexer function\n",
        "tokens = lexer(input_text)  # Tokenize the input\n",
        "token_list = renderTokens(tokens)\n",
        "print(f\"\\nToken List:{token_list}\")\n",
        "\n",
        "# Tokenize the user input using the enhanced_lexer function\n",
        "print(\"Tokens:\", tokens)\n",
        "en_tokens = enhanced_lexer(input_text)\n",
        "en_token_list = renderTokens(en_tokens)\n",
        "print(f\"\\nToken List:{en_token_list}\")\n",
        "\n",
        "parsed_ast = parse(token_list)  # Parse the tokens and generate an AST\n",
        "\n",
        "is_input_palindrome = is_palindrome(parsed_ast)  # Check if the parsed input is a palindrome\n",
        "if is_input_palindrome:  # If it's a palindrome\n",
        "    print(f\"The input '{parsed_ast}' is a palindrome.\")  # Print the message indicating it's a palindrome\n",
        "else:  # If it's not a palindrome\n",
        "    print(f\"The input '{parsed_ast}' is not a palindrome.\")  # Print the message indicating it's not a palindrome"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
